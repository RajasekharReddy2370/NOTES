Self Introduction:
                  This is Rajasekhar Reddy, and I‚Äôm from Palnadu Andhra Pradesh. 
                  I have 1.10 year professional experience in software development, with a strong focus on Python programming.
                  My primary expertise lies in developing web applications using the Django framework and building RESTful services 
                  with Django REST Framework. I have worked with various databases including MySQL, PostgreSQL, and MongoDB, 
                  and I am comfortable in both relational and NoSQL environments.
                  In addition to backend development, I have basic knowledge of HTML and CSS, which helps me collaborate effectively with frontend teams. 
                  I also have hands-on experience with tools like Git for version control, Docker for containerization, 
                  and have used Tableau and Advanced Excel for data visualization and reporting tasks.
                  I am passionate about clean, efficient code and continuously improving my technical skills. 
                  I look forward to contributing to a dynamic team where I can grow further as a backend developer.
######################################################################################################################################
                                                                HR QUESTIONS
######################################################################################################################################

1. WHY DO YOU WANT TO CHANGE YOUR COMPANY?
    I am looking for new opportunities to further expand my skills and work on more challenging and innovative projects. While I have gained valuable experience in my current role, 
    I believe that moving to a new company will provide me with the opportunity to work with different technologies, enhance my problem-solving abilities, and contribute to impactful projects. 
    I'm excited about the possibility of growing professionally in a dynamic environment and collaborating with talented teams.

    I‚Äôm looking for new opportunities to grow my skills and take on more challenging projects. 
    While I‚Äôve learned a lot in my current role, 
    I believe joining a new company will give me the chance to work with different technologies, improve my problem-solving skills, 
    and contribute to meaningful projects. 
    I‚Äôm excited to grow professionally and work with a talented team.

2. WHAT IS YOUR NOTICE PERIOD? IF HE NEEDS IMMEDIATE JOINER how to manage?
    As per the company's policy, the standard notice period is 45 days; however,
I am open to negotiating with management once the offer is confirmed.

3. What are your salary expectations?
Im expecting ‚Çπ5 LPA because I‚Äôve gained solid experience in backend development and have taken on more responsibilities.
Based on my skills and industry standards, I feel this is a fair expectation.

It‚Äôs a startup, so they‚Äôre still growing and focusing on building the business. Because of budget limits, 
salary hikes weren‚Äôt a priority. I‚Äôve learned a lot there, but I‚Äôm now looking for a role where I can grow both professionally and financially

######################################################################################################################################
                                                                Itoconnect
######################################################################################################################################

user
subuser
pollingbooth
ward issues

IToConnect is a public relations management system designed for managing voter data efficiently.
Once the user onboarded to the application, admin of the application should be given access to the users inorder to use the services
user also given access to create sub-users and allocate the polling booths, villages to them, 
so that the sub-user will only have the access to those polling booth related voters.
Sub-users can go on the field and they will make the surveys related to ward-issues, 
Top hierarchy users will be able to see the graphs related to favour votes and the issues reported by the sub-user.

Django as a framework,
Backend is with python
Frontend is built with ReactJS
connection using API's
Database - Mysql

ROLES:-
API Development and Integration : 
Develop RESTful APIs using Django REST Framework (DRF) to connect the backend with the ReactJS frontend.
Ensure API endpoints are secure, efficient, and well-documented.

Database Management:
Design and manage database schemas for MySQL to store user data, voter information, polling booths, surveys, and other related data.
Write optimized and secure SQL queries for CRUD operations.
Handle database migrations using Django's migration system.



######################################################################################################################################
                                                            RFID
#######################################################################################################################################

I worked as a backend developer on an RFID-based inventory tracking system. I developed the backend using Django and Django REST Framework. 
In the system, RFID readers scanned nearby tags and published the tag data to an MQTT broker. Our backend subscribed to these MQTT topics, 
processed the incoming tag IDs, mapped them to registered products, and updated their status and location in real time. 
The frontend consumed REST APIs from our backend to display live tracking of inventory.

I was responsible for designing the database models, creating REST APIs for item and tag management, 
implementing Start/Stop commands for controlling the RFID readers, and handling authentication and permissions. 
I also optimized database operations and message handling to improve the overall scanning performance and reduce duplicate reads



######################################################################################################################################
                                                            SHIPPER-COPILOT
#######################################################################################################################################

Overview : 
This application is built on python django framework. Where we have made a REST API which recieves the payload from the shippercopilot application. 
The payload consists of different parameters including : 
    question : this is the question asked by the user in the chatbot UI.
    X-Token : which is used to consume node API's with which we make the shipments.
    node_endpoint : this is the micro-service endpoint.
    carrier_endpoint : this is the micro-service to send the order to the carriers.
    location_id : this is the user ID with which we filter the details for the user question.
    environment : this is the environment from where the API is consumed (dev, demo)

In the API we consume openAI API to get the user intent. Here we have used the agentic approach where each agent is responsible for making decision based on the prompt given to it. We have three agents. 
    Agent 1 : The agent analyzes the language and context of your query to identify whether it‚Äôs a GET or POST request, streamlining your interactions
    Agent 2 : When you ask a question about retrieving data (like querying a database for specific information), the agent identifies it as a GET request and generates the appropriate SQL query for you (in the prompt we give the schema of the tables we needed.)
    Agent 3 : The agent extracts relevant details from user question and creates a precise JSON object that contains - person name, company name, product name, carrier name

    If the question is related to GET then we create the sql query for it and send back the query in the response.
    If the question is related to POST then we connect to the postgres database and get the address details, product details, 
user location (from address), carrier details. If user question doesn't have key related to the carrier then default carrier is picked.
We also ensure if the shipment is internationl, in this case we only query the international carrier services only and choose one randomly. 
If address or product are in multiple then we send back all the formated details back in the response where user will select one and send back the payload to another API. 
For all success response we have added 'type' keyword where it defines the response object type (MULTIPLE, LABLE, SQL, SHIP)


######################################################################################################################################
                                                            AIVOICE
#######################################################################################################################################

Generate the voice of any person based on their related data such as voice
processing the voice files 

Developed an end-to-end automation pipeline for processing YouTube videos,
integrating audio processing, transcription, and training workflows through a custom-built website.

Engineered a module for video-to-audio conversion, denoising,
and parallel uploading to Amazon S3 for efficient data storage and processing.

youtube links
denoising
clips cutting
genarate transcripts [extracting text from voice] using Speech recognition
check text of the particular voice is correct or not
checking parameters of the voice(samplrate,channels,pcmformat etc)
training (inference training)
model

######################################################################################################################################
                                                              RAG
######################################################################################################################################

Developed a Retrieval-Augmented Generation (RAG) application leveraging LangChain and
ChromaDB to enhance the accuracy and relevance of AI-generated responses.
Integrated ChromaDB as a vector database for efficient and scalable embedding storage and retrieval in the application.


######################################################################################################################################
                                                              PREP
######################################################################################################################################


1Ô∏è‚É£ Explain about yourself

I am a Python Developer with around 1 year and 10 months of experience in building backend applications and data-driven solutions.
I have worked extensively with Python, Django, Flask, and Django REST Framework to develop RESTful APIs for SaaS, logistics, and AI-based applications.
Along with backend development, I also have strong exposure to data analysis using Pandas, SQL, Advanced Excel, and data visualization tools like Tableau and Power BI.
My focus has always been on writing clean, scalable code, automating manual processes, and converting raw data into meaningful insights.

2Ô∏è‚É£ Explain the work you do and your role

My role mainly involves backend development, data handling, and API integration.
I design and develop REST APIs using Django REST Framework, handle database operations using MySQL and PostgreSQL, and manage authentication, permissions, and user roles.
I also work on data cleaning, analysis, automation of reports, and dashboard creation.
In some projects, I handled asynchronous tasks and performance improvements, ensuring smooth and secure application flow.

3Ô∏è‚É£ What have you done in Python?

Using Python, I have:

Built RESTful APIs using Django and Flask

Cleaned and processed large datasets using Pandas and NumPy

Automated reporting tasks to reduce manual effort

Implemented user authentication, role management, and permissions

Integrated databases using SQL and ORM

Worked with IoT data and real-time message handling using MQTT

Handled asynchronous processing for background tasks

Overall, Python has been my primary tool for backend development, data processing, and automation.

4Ô∏è‚É£ Why did you use Tableau?

I used Tableau mainly for data visualization and storytelling.
While Python and SQL handle data processing, Tableau helps convert processed data into visual insights that are easy for non-technical stakeholders to understand.
It allows faster analysis, interactive dashboards, and better decision-making compared to static reports.

5Ô∏è‚É£ What type of reports did you generate?

I generated:

Operational reports (daily, weekly, monthly performance)

Business summary reports

Trend analysis reports

Data quality and validation reports

KPI-based dashboards

Automation-based reports where data refresh happens automatically

6Ô∏è‚É£ What type of graphs did you use?

Based on the requirement, I used:

Bar charts for comparison

Line charts for trends over time

Pie charts for percentage distribution

Heat maps for intensity and performance

Tables with filters for detailed analysis

Combined charts for KPI dashboards

7Ô∏è‚É£ What type of dashboards did you create?

I created:

Management dashboards showing KPIs

Performance dashboards with trends and comparisons

Operational dashboards for daily tracking

Interactive dashboards with filters, drill-downs, and date selection
These dashboards helped stakeholders track performance in real time.

8Ô∏è‚É£ Explain the projects you mentioned
üîπ ITOCONNECT

This is a SaaS application where I developed backend APIs using Django REST Framework.
I worked on user roles, sub-user access, permission handling, and custom authentication.
The system was designed as a secure multi-tenant application with scalable models and middleware support.

üîπ AI-VOICE

This project involved building REST APIs for a Text-to-Speech system.
Users could train voice models and perform audio inference.
I worked on API development, tracking training progress using dynamic templates, and improving backend performance while handling asynchronous processing.

üîπ SHIPPER COPILOT

This is a logistics platform based on RFID and IoT.
I developed APIs for product tracking and logistics data.
Used MQTT protocol to track real-time product movement and encoded RFID tags based on GS1 standards to maintain uniqueness and global compatibility.

9Ô∏è‚É£ What achievements did you make?

Some of my key achievements include:

Automated data analysis and reporting, reducing manual effort significantly

Improved backend performance in API-heavy applications

Successfully implemented role-based access control in SaaS systems

Delivered real-time tracking solutions using IoT and RFID

Converted complex raw data into meaningful dashboards used by management

üîü What issues did you face and how did you solve them?

I faced issues such as:

Handling large datasets efficiently ‚Üí solved using optimized Pandas operations and SQL queries

API performance bottlenecks ‚Üí resolved using better query optimization and async processing

Authentication and permission complexity ‚Üí solved by customizing Django User model and middleware

Real-time data handling challenges ‚Üí addressed using MQTT and structured data pipelines
Each issue helped me improve debugging skills, performance tuning, and system design understanding.


Why are you expecting 6.5 LPA?

I am expecting 6.5 LPA because of my hands-on experience as a Django Backend Developer and the kind of responsibilities I currently handle.
I have around 1.6 years of real project experience in Django, where I‚Äôve built production-level REST APIs, implemented authentication and role-based access, optimized database queries, and worked on scalable backend systems.
I‚Äôve contributed to end-to-end backend development in multiple projects, not just maintenance work.
Based on my skill set, market standards for Django developers with my experience, and the value I can bring to the team from day one, I feel 6.5 LPA is a reasonable and fair expectation

Since this is the early stage of my career, I want to learn more through hands-on development work.
In my current role, the work is mainly support and maintenance oriented, so the learning exposure in Django development is limited.
I‚Äôm looking for a role where I can work more on core Django backend development, build APIs, and grow my technical skills.
That‚Äôs why I‚Äôm considering this change early in my career
