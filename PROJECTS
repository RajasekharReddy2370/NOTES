Self Introduction:
                  Good [morning/afternoon], my name is Rajasekhar Reddy, and I’m from Andhra Pradesh. 
                  I have 1 year professional experience in software development, with a strong focus on Python programming.
                  My primary expertise lies in developing web applications using the Django framework and building RESTful services 
                  with Django REST Framework. I have worked with various databases including MySQL, PostgreSQL, and MongoDB, 
                  and I am comfortable in both relational and NoSQL environments.
                  In addition to backend development, I have basic knowledge of HTML and CSS, which helps me collaborate effectively with frontend teams. 
                  I also have hands-on experience with tools like Git for version control, Docker for containerization, 
                  and have used Tableau and Advanced Excel for data visualization and reporting tasks.
                  I am passionate about clean, efficient code and continuously improving my technical skills. 
                  I look forward to contributing to a dynamic team where I can grow further as a backend developer.
######################################################################################################################################
                                                                HR QUESTIONS
######################################################################################################################################

1. WHY DO YOU WANT TO CHANGE YOUR COMPANY?
    I am looking for new opportunities to further expand my skills and work on more challenging and innovative projects. While I have gained valuable experience in my current role, 
    I believe that moving to a new company will provide me with the opportunity to work with different technologies, enhance my problem-solving abilities, and contribute to impactful projects. 
    I'm excited about the possibility of growing professionally in a dynamic environment and collaborating with talented teams.

    I’m looking for new opportunities to grow my skills and take on more challenging projects. 
    While I’ve learned a lot in my current role, 
    I believe joining a new company will give me the chance to work with different technologies, improve my problem-solving skills, 
    and contribute to meaningful projects. 
    I’m excited to grow professionally and work with a talented team.

2. WHAT IS YOUR NOTICE PERIOD? IF HE NEEDS IMMEDIATE JOINER how to manage?
    As per the company's policy, the standard notice period is 45 days; however,
I am open to negotiating with management once the offer is confirmed.

3. What are your salary expectations?
Im expecting ₹5 LPA because I’ve gained solid experience in backend development and have taken on more responsibilities.
Based on my skills and industry standards, I feel this is a fair expectation.

It’s a startup, so they’re still growing and focusing on building the business. Because of budget limits, 
salary hikes weren’t a priority. I’ve learned a lot there, but I’m now looking for a role where I can grow both professionally and financially

######################################################################################################################################
                                                                Itoconnect
######################################################################################################################################

user
subuser
pollingbooth
ward issues

IToConnect is a public relations management system designed for managing voter data efficiently.
Once the user onboarded to the application, admin of the application should be given access to the users inorder to use the services
user also given access to create sub-users and allocate the polling booths, villages to them, 
so that the sub-user will only have the access to those polling booth related voters.
Sub-users can go on the field and they will make the surveys related to ward-issues, 
Top hierarchy users will be able to see the graphs related to favour votes and the issues reported by the sub-user.

Django as a framework,
Backend is with python
Frontend is built with ReactJS
connection using API's
Database - Mysql

ROLES:-
API Development and Integration : 
Develop RESTful APIs using Django REST Framework (DRF) to connect the backend with the ReactJS frontend.
Ensure API endpoints are secure, efficient, and well-documented.

Database Management:
Design and manage database schemas for MySQL to store user data, voter information, polling booths, surveys, and other related data.
Write optimized and secure SQL queries for CRUD operations.
Handle database migrations using Django's migration system.



######################################################################################################################################
                                                            RFID
#######################################################################################################################################





######################################################################################################################################
                                                            SHIPPER-COPILOT
#######################################################################################################################################

Overview : 
This application is built on python django framework. Where we have made a REST API which recieves the payload from the shippercopilot application. 
The payload consists of different parameters including : 
    question : this is the question asked by the user in the chatbot UI.
    X-Token : which is used to consume node API's with which we make the shipments.
    node_endpoint : this is the micro-service endpoint.
    carrier_endpoint : this is the micro-service to send the order to the carriers.
    location_id : this is the user ID with which we filter the details for the user question.
    environment : this is the environment from where the API is consumed (dev, demo)

In the API we consume openAI API to get the user intent. Here we have used the agentic approach where each agent is responsible for making decision based on the prompt given to it. We have three agents. 
    Agent 1 : The agent analyzes the language and context of your query to identify whether it’s a GET or POST request, streamlining your interactions
    Agent 2 : When you ask a question about retrieving data (like querying a database for specific information), the agent identifies it as a GET request and generates the appropriate SQL query for you (in the prompt we give the schema of the tables we needed.)
    Agent 3 : The agent extracts relevant details from user question and creates a precise JSON object that contains - person name, company name, product name, carrier name

    If the question is related to GET then we create the sql query for it and send back the query in the response.
    If the question is related to POST then we connect to the postgres database and get the address details, product details, 
user location (from address), carrier details. If user question doesn't have key related to the carrier then default carrier is picked.
We also ensure if the shipment is internationl, in this case we only query the international carrier services only and choose one randomly. 
If address or product are in multiple then we send back all the formated details back in the response where user will select one and send back the payload to another API. 
For all success response we have added 'type' keyword where it defines the response object type (MULTIPLE, LABLE, SQL, SHIP)


######################################################################################################################################
                                                            AIVOICE
#######################################################################################################################################

Generate the voice of any person based on their related data such as voice
processing the voice files 

Developed an end-to-end automation pipeline for processing YouTube videos,
integrating audio processing, transcription, and training workflows through a custom-built website.

Engineered a module for video-to-audio conversion, denoising,
and parallel uploading to Amazon S3 for efficient data storage and processing.

youtube links
denoising
clips cutting
genarate transcripts [extracting text from voice] using Speech recognition
check text of the particular voice is correct or not
checking parameters of the voice(samplrate,channels,pcmformat etc)
training (inference training)
model

######################################################################################################################################
                                                              RAG
######################################################################################################################################

Developed a Retrieval-Augmented Generation (RAG) application leveraging LangChain and
ChromaDB to enhance the accuracy and relevance of AI-generated responses.
Integrated ChromaDB as a vector database for efficient and scalable embedding storage and retrieval in the application.
